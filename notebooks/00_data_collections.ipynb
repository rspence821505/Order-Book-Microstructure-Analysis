{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a49c17",
   "metadata": {},
   "source": "## **Data Collection - Polygon.io Integration**\n\n**Purpose:** Get raw data from Polygon.io and save it to disk\n\n**What it does:**\n\n- Downloads/loads trade, quote (NBBO), and L2 LOB data from Polygon.io\n- Initial data quality checks (missing values, timestamps, gaps)\n- Saves cleaned raw data to `data/interim/`\n- Basic exploratory data analysis (EDA) to understand the data\n\n**Data Sources:**\n- **Trades**: Individual trade tick data from `/v3/trades/{ticker}`\n- **Quotes**: NBBO (National Best Bid/Offer) quote data\n- **LOB**: L2 aggregated order book snapshots"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef88043",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# 00_data_collection.ipynb\n# Purpose: Load and validate raw data from Polygon.io\n# ============================================================================\n\n# %% Imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nfrom datetime import datetime\n\n# Visualization settings\nplt.style.use('seaborn-v0_8-paper')  \nplt.rcParams.update({\n    'font.family': 'serif',\n    'font.weight': 'bold',        \n    'axes.labelweight': 'bold',    \n    'axes.titleweight': 'bold',   \n    'axes.linewidth': 1.2,\n    'axes.spines.top': False,\n    'axes.spines.right': False,\n})\n%matplotlib inline\n\nfrom src.config import RAW_DATA_DIR, INTERIM_DATA_DIR, FIGURES_DIR\nfrom src.data.polygon_trade_loader import load_polygon_trades, PolygonTradeLoader\nfrom src.data.polygon_quote_loader import load_polygon_quotes, PolygonQuoteLoader\nfrom src.data.polygon_lob_loader import load_polygon_lob, PolygonLOBLoader\nfrom src.data.synchronizer import align_trades_quotes\nfrom src.utils.data_quality import (\n    check_data_quality,\n    print_quality_report,\n    detect_gaps,\n    remove_outliers\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b7992a",
   "metadata": {},
   "outputs": [],
   "source": "# %% Configuration\nTICKER = \"AAPL\"  # U.S. equity ticker\nSTART_DATE = \"2024-01-01\"  # Optional: specify date range\nEND_DATE = None  # None = use most recent data\n\n# Data source selection\nDATA_SOURCE = \"local\"  # \"local\" = load from disk, \"api\" = fetch from Polygon.io\n\nprint(f\"Ticker: {TICKER}\")\nprint(f\"Data source: {DATA_SOURCE}\")\nif START_DATE:\n    print(f\"Date range: {START_DATE} to {END_DATE or 'latest'}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffcff2",
   "metadata": {},
   "outputs": [],
   "source": "# %% Note about data collection\n# To collect new data from Polygon.io, you can:\n# 1. Use the API directly (requires Polygon.io API key)\n# 2. Or run data collection scripts (to be implemented):\n#    python scripts/collect_polygon_data.py --ticker AAPL --start-date 2024-01-01\n#\n# This notebook assumes data has already been collected and saved to disk."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960074fb",
   "metadata": {},
   "outputs": [],
   "source": "# %% Load data from Polygon.io\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"LOADING POLYGON.IO DATA\")\nprint(\"=\" * 60)\n\n# Load trade data\nprint(\"\\n1. Loading trade data...\")\ntry:\n    trades_df = load_polygon_trades(\n        ticker=TICKER,\n        start_date=START_DATE,\n        end_date=END_DATE,\n        filter_regular=True  # Exclude odd-lots, out-of-sequence, etc.\n    )\n    print(f\"   Loaded {len(trades_df):,} trades\")\n    print(f\"   Columns: {trades_df.columns.tolist()}\")\nexcept Exception as e:\n    print(f\"   Error loading trades: {e}\")\n    trades_df = None\n\n# Load quote data (NBBO)\nprint(\"\\n2. Loading NBBO quote data...\")\ntry:\n    quotes_df = load_polygon_quotes(\n        ticker=TICKER,\n        start_date=START_DATE,\n        end_date=END_DATE,\n        compute_features=True  # Compute spread, mid-price, etc.\n    )\n    print(f\"   Loaded {len(quotes_df):,} quotes\")\n    print(f\"   Columns: {quotes_df.columns.tolist()}\")\nexcept Exception as e:\n    print(f\"   Error loading quotes: {e}\")\n    quotes_df = None\n\n# Load LOB data (L2 snapshots)\nprint(\"\\n3. Loading L2 order book snapshots...\")\ntry:\n    lob_df = load_polygon_lob(\n        ticker=TICKER,\n        start_date=START_DATE,\n        end_date=END_DATE,\n        depth=10,  # Load top 10 levels\n        compute_features=True  # Compute book shape features\n    )\n    print(f\"   Loaded {len(lob_df):,} snapshots\")\n    print(f\"   Columns: {lob_df.columns.tolist()}\")\nexcept Exception as e:\n    print(f\"   Error loading LOB: {e}\")\n    lob_df = None\n\nprint(\"\\n\" + \"=\" * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eac5e8d",
   "metadata": {},
   "outputs": [],
   "source": "# %% Inspect quote data (NBBO)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"QUOTE DATA INSPECTION (NBBO)\")\nprint(\"=\" * 60)\n\nif quotes_df is not None:\n    display(quotes_df.head())\n    print(f\"\\nShape: {quotes_df.shape}\")\n    print(f\"\\nData types:\\n{quotes_df.dtypes}\")\n    print(f\"\\nSample statistics:\")\n    print(quotes_df[['bid_price', 'ask_price', 'bid_size', 'ask_size']].describe())\nelse:\n    print(\"No quote data available\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df6a1c",
   "metadata": {},
   "outputs": [],
   "source": "# %% Inspect trade data\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TRADE DATA INSPECTION\")\nprint(\"=\" * 60)\n\nif trades_df is not None:\n    display(trades_df.head())\n    print(f\"\\nShape: {trades_df.shape}\")\n    print(f\"\\nData types:\\n{trades_df.dtypes}\")\n    print(f\"\\nTrade statistics:\")\n    print(trades_df[['price', 'size']].describe())\n    \n    # Check trade classification if available\n    if 'is_aggressive_buy' in trades_df.columns:\n        n_buys = trades_df['is_aggressive_buy'].sum()\n        n_sells = trades_df['is_aggressive_sell'].sum()\n        print(f\"\\nTrade classification:\")\n        print(f\"  Aggressive buys: {n_buys:,} ({n_buys/len(trades_df)*100:.1f}%)\")\n        print(f\"  Aggressive sells: {n_sells:,} ({n_sells/len(trades_df)*100:.1f}%)\")\nelse:\n    print(\"No trade data available\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c250cf55",
   "metadata": {},
   "outputs": [],
   "source": "# %% Inspect LOB data (L2 snapshots)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"ORDER BOOK DATA INSPECTION (L2)\")\nprint(\"=\" * 60)\n\nif lob_df is not None:\n    display(lob_df.head())\n    print(f\"\\nShape: {lob_df.shape}\")\n    print(f\"\\nData types:\\n{lob_df.dtypes.head(20)}\")\n    \n    # Check for computed features\n    if 'quoted_spread' in lob_df.columns:\n        print(f\"\\nOrder book statistics:\")\n        print(f\"  Average spread: ${lob_df['quoted_spread'].mean():.4f}\")\n        if 'relative_spread' in lob_df.columns:\n            print(f\"  Average spread (bps): {lob_df['relative_spread'].mean()*10000:.2f}\")\n        if 'depth_at_best' in lob_df.columns:\n            print(f\"  Average depth at best: {lob_df['depth_at_best'].mean():.0f} shares\")\nelse:\n    print(\"No LOB data available\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88731000",
   "metadata": {},
   "outputs": [],
   "source": "# %% Data quality checks\nprint(\"\\n\" + \"=\" * 60)\nprint(\"DATA QUALITY ANALYSIS\")\nprint(\"=\" * 60)\n\n# Check quote data quality (most comprehensive)\nif quotes_df is not None:\n    print(\"\\nChecking quote (NBBO) data quality...\")\n    quality_report = check_data_quality(quotes_df, timestamp_col=\"timestamp\")\n    print_quality_report(quality_report)\nelse:\n    print(\"No quote data available for quality checks\")\n\n# Check trade data quality\nif trades_df is not None:\n    print(\"\\n\\nChecking trade data quality...\")\n    quality_report = check_data_quality(trades_df, timestamp_col=\"timestamp\")\n    print_quality_report(quality_report)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded3cf8b",
   "metadata": {},
   "outputs": [],
   "source": "# %% Check for time gaps\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TIME GAP ANALYSIS\")\nprint(\"=\" * 60)\n\n# Check gaps in quote data\nif quotes_df is not None:\n    print(\"\\nAnalyzing gaps in quote data...\")\n    gaps = detect_gaps(quotes_df, timestamp_col=\"timestamp\", max_gap_seconds=60.0)\n    if len(gaps) > 0:\n        print(f\"   Found {len(gaps)} gaps > 60s:\")\n        display(gaps.head())\n    else:\n        print(\"   No significant time gaps found in quotes\")\n\n# Check gaps in trade data\nif trades_df is not None:\n    print(\"\\nAnalyzing gaps in trade data...\")\n    gaps = detect_gaps(trades_df, timestamp_col=\"timestamp\", max_gap_seconds=300.0)\n    if len(gaps) > 0:\n        print(f\"   Found {len(gaps)} gaps > 300s:\")\n        display(gaps.head())\n    else:\n        print(\"   No significant time gaps found in trades\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dcc6ef",
   "metadata": {},
   "outputs": [],
   "source": "# %% Visualize quote data\nprint(\"\\n\" + \"=\" * 60)\nprint(\"VISUALIZATIONS\")\nprint(\"=\" * 60)\n\nif quotes_df is not None and len(quotes_df) > 0:\n    fig, axes = plt.subplots(3, 1, figsize=(15, 10))\n    \n    # Best bid/ask prices (NBBO)\n    axes[0].plot(quotes_df[\"timestamp\"], quotes_df[\"bid_price\"], label=\"Bid\", linewidth=1.0, alpha=0.7)\n    axes[0].plot(quotes_df[\"timestamp\"], quotes_df[\"ask_price\"], label=\"Ask\", linewidth=1.0, alpha=0.7)\n    if 'mid_price' in quotes_df.columns:\n        axes[0].plot(quotes_df[\"timestamp\"], quotes_df[\"mid_price\"], label=\"Mid\", linewidth=0.8, alpha=0.5)\n    axes[0].set_title(f\"{TICKER} - Best Bid/Ask Prices Over Time (NBBO)\")\n    axes[0].set_ylabel(\"Price ($)\")\n    axes[0].legend()\n    axes[0].grid(True, alpha=0.3)\n    \n    # Spread\n    if 'quoted_spread' in quotes_df.columns:\n        spread = quotes_df['quoted_spread']\n    else:\n        spread = quotes_df[\"ask_price\"] - quotes_df[\"bid_price\"]\n    axes[1].plot(quotes_df[\"timestamp\"], spread, linewidth=1.0, color=\"orange\", alpha=0.7)\n    axes[1].set_title(\"Bid-Ask Spread Over Time\")\n    axes[1].set_ylabel(\"Spread ($)\")\n    axes[1].grid(True, alpha=0.3)\n    \n    # Volume at best bid/ask\n    axes[2].plot(\n        quotes_df[\"timestamp\"], quotes_df[\"bid_size\"], label=\"Bid Size\", linewidth=0.5, alpha=0.7\n    )\n    axes[2].plot(\n        quotes_df[\"timestamp\"], quotes_df[\"ask_size\"], label=\"Ask Size\", linewidth=0.5, alpha=0.7\n    )\n    axes[2].set_title(\"Size at Best Bid/Ask (NBBO)\")\n    axes[2].set_ylabel(\"Size (shares)\")\n    axes[2].set_xlabel(\"Time\")\n    axes[2].legend()\n    axes[2].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig(FIGURES_DIR / f\"{TICKER}_quote_data_overview.png\", dpi=300, bbox_inches=\"tight\")\n    plt.show()\n    print(f\"\\nSaved visualization to: {FIGURES_DIR / f'{TICKER}_quote_data_overview.png'}\")\nelse:\n    print(\"No quote data available for visualization\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd6e9ba",
   "metadata": {},
   "outputs": [],
   "source": "# %% Handle missing values and outliers\nprint(\"\\n\" + \"=\" * 60)\nprint(\"DATA CLEANING\")\nprint(\"=\" * 60)\n\n# Clean quote data\nif quotes_df is not None:\n    print(\"\\nCleaning quote data...\")\n    print(f\"  Before cleaning: {len(quotes_df):,} rows\")\n    \n    # Drop missing values\n    quotes_df_clean = quotes_df.dropna()\n    print(f\"  After dropping NaN: {len(quotes_df_clean):,} rows\")\n    \n    # Remove outliers (optional - be conservative)\n    price_cols = [\"bid_price\", \"ask_price\"]\n    quotes_df_clean = remove_outliers(\n        quotes_df_clean, columns=price_cols, method=\"iqr\", threshold=3.0, verbose=True\n    )\n    print(f\"  After outlier removal: {len(quotes_df_clean):,} rows\")\nelse:\n    quotes_df_clean = None\n    print(\"No quote data to clean\")\n\n# Clean trade data\nif trades_df is not None:\n    print(\"\\nCleaning trade data...\")\n    print(f\"  Before cleaning: {len(trades_df):,} rows\")\n    \n    # Drop missing values\n    trades_df_clean = trades_df.dropna()\n    print(f\"  After dropping NaN: {len(trades_df_clean):,} rows\")\n    \n    # Remove outliers\n    trades_df_clean = remove_outliers(\n        trades_df_clean, columns=['price'], method=\"iqr\", threshold=3.0, verbose=True\n    )\n    print(f\"  After outlier removal: {len(trades_df_clean):,} rows\")\nelse:\n    trades_df_clean = None\n    print(\"No trade data to clean\")\n\n# Clean LOB data\nif lob_df is not None:\n    print(\"\\nCleaning LOB data...\")\n    print(f\"  Before cleaning: {len(lob_df):,} rows\")\n    \n    # Drop missing values\n    lob_df_clean = lob_df.dropna()\n    print(f\"  After dropping NaN: {len(lob_df_clean):,} rows\")\nelse:\n    lob_df_clean = None\n    print(\"No LOB data to clean\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec54d94d",
   "metadata": {},
   "outputs": [],
   "source": "# %% Save cleaned data\nprint(\"\\n\" + \"=\" * 60)\nprint(\"SAVING CLEANED DATA\")\nprint(\"=\" * 60)\n\nINTERIM_DATA_DIR.mkdir(parents=True, exist_ok=True)\n\n# Save quote data\nif quotes_df_clean is not None:\n    output_file = INTERIM_DATA_DIR / f\"{TICKER}_quotes_cleaned.parquet\"\n    quotes_df_clean.to_parquet(output_file, index=False)\n    print(f\"\\n Saved cleaned quote data to: {output_file}\")\n    print(f\"  File size: {output_file.stat().st_size / 1024 / 1024:.2f} MB\")\n    print(f\"  Records: {len(quotes_df_clean):,}\")\n\n# Save trade data\nif trades_df_clean is not None:\n    output_file = INTERIM_DATA_DIR / f\"{TICKER}_trades_cleaned.parquet\"\n    trades_df_clean.to_parquet(output_file, index=False)\n    print(f\"\\n Saved cleaned trade data to: {output_file}\")\n    print(f\"  File size: {output_file.stat().st_size / 1024 / 1024:.2f} MB\")\n    print(f\"  Records: {len(trades_df_clean):,}\")\n\n# Save LOB data\nif lob_df_clean is not None:\n    output_file = INTERIM_DATA_DIR / f\"{TICKER}_lob_cleaned.parquet\"\n    lob_df_clean.to_parquet(output_file, index=False)\n    print(f\"\\n Saved cleaned LOB data to: {output_file}\")\n    print(f\"  File size: {output_file.stat().st_size / 1024 / 1024:.2f} MB\")\n    print(f\"  Records: {len(lob_df_clean):,}\")\n\n# %% Summary\nprint(\"\\n\" + \"=\" * 60)\nprint(\"SUMMARY\")\nprint(\"=\" * 60)\n\nif quotes_df_clean is not None:\n    print(f\"\\n Loaded {len(quotes_df_clean):,} clean quote snapshots (NBBO)\")\n    print(f\"  Time range: {quotes_df_clean['timestamp'].min()} to {quotes_df_clean['timestamp'].max()}\")\n\nif trades_df_clean is not None:\n    print(f\"\\n Loaded {len(trades_df_clean):,} clean trades\")\n    print(f\"  Time range: {trades_df_clean['timestamp'].min()} to {trades_df_clean['timestamp'].max()}\")\n\nif lob_df_clean is not None:\n    print(f\"\\n Loaded {len(lob_df_clean):,} clean LOB snapshots\")\n    print(f\"  Time range: {lob_df_clean['timestamp'].min()} to {lob_df_clean['timestamp'].max()}\")\n\nprint(f\"\\n Data saved to: {INTERIM_DATA_DIR}\")\nprint(f\"\\n Next notebook: Run 10_basic_features.ipynb\")"
  },
  {
   "cell_type": "code",
   "id": "zbyt0frnm0i",
   "source": "# %% Optional: Align trades with quotes (for trade classification)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TRADE-QUOTE ALIGNMENT (OPTIONAL)\")\nprint(\"=\" * 60)\n\nif trades_df_clean is not None and quotes_df_clean is not None:\n    print(\"\\nAligning trades with quotes using Lee-Ready method...\")\n    \n    # Align trades with the most recent quote before each trade (as-of merge)\n    aligned_df = align_trades_quotes(\n        trades_df_clean,\n        quotes_df_clean,\n        method='asof',\n        tolerance='10ms'  # Maximum time difference allowed\n    )\n    \n    print(f\"  Aligned {len(aligned_df):,} trades with quotes\")\n    print(f\"\\nSample aligned data:\")\n    display(aligned_df[['timestamp', 'price', 'size', 'bid_price', 'ask_price', 'mid_price']].head())\n    \n    # Save aligned data\n    output_file = INTERIM_DATA_DIR / f\"{TICKER}_trades_aligned.parquet\"\n    aligned_df.to_parquet(output_file, index=False)\n    print(f\"\\n Saved aligned data to: {output_file}\")\nelse:\n    print(\"Both trade and quote data are required for alignment\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orderbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}